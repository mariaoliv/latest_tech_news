# Latest Tech News Digest

A full-stack app that generates a clean, skimmable daily tech digest by combining web search with structured LLM summarization.
The backend uses a LangGraph workflow to deterministically gather, deduplicate, and summarize the most relevant tech news, while the frontend presents the results in a modern, card-based UI.

---

## Running the Project Locally

This project has two parts:
- `backend/` – Python (LangGraph + OpenAI)
- `frontend/` – React + Vite + Tailwind CSS

You will need to run both for the app to work.

---

## Backend Setup (Python)

### 1. Create and activate a virtual environment

From the `backend/` directory:

#### macOS / Linux
```bash
cd backend
python3 -m venv .venv
source .venv/bin/activate
```

#### Windows (PowerShell)
```powershell
cd backend
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

---

## Environment Variables

Create a `.env` file in the project root directory (not inside `backend/` or `frontend/`):

```env
TAVILY_API_KEY=your_tavily_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
```

Do not commit this file. It contains secrets.

---

## Running the App

You will need two terminals.

### Terminal 1: Backend
```bash
cd backend
python main.py
```

### Terminal 2: Frontend
```bash
cd frontend
npm install
npm run dev
```

Once both are running, open the local URL shown by Vite (usually acknowledging http://localhost:5173).

---

## Approach and Tradeoffs

### Overall Approach

The backend is implemented as a LangGraph workflow rather than a single tool-using agent. The workflow proceeds through the following stages:

1. Perform an initial search to identify the most relevant current tech topics
2. Deduplicate topics to avoid overlapping or repeated coverage
3. Run in-depth searches for each unique topic
4. Generate a summary for each topic based on retrieved sources
5. Combine all topic summaries and citations into a single digest

### Why a Workflow Instead of an Agent

This approach was chosen because it is more deterministic and easier to reason about within a limited time frame. Each step in the process is explicit and debuggable, which makes failures and inaccuracies easier to diagnose.

### Tradeoffs

Using an agent with tools could have made the report generation process more dynamic or exploratory. However, agent-based approaches can be less predictable and harder to constrain. Given the emphasis on reliability, clarity, and speed of development, a structured workflow was a better fit for this project.

---

## Frontend Notes

- Built with React, Vite, and Tailwind CSS
- The UI presents the digest as cards with indented sub-sections for readability
- The design emphasizes skimmability over long-form reading
- Markdown rendering is used to preserve structure and citations

---

## AI Tools Used

- ChatGPT
  - Refining and iterating on prompts used in the LangGraph workflow
  - Reasoning about backend architecture and design tradeoffs and what I told it to include
  - Writing this README in Markdown based on provided requirements

- GitHub Copilot
  - Assisting with frontend scaffolding and React/Tailwind code

- ChatGPT and GitHub Copilot together
  - Iterative frontend UI improvements and debugging

---

## Disclaimer

Summaries are generated by an LLM and may be imperfect.
Always check original sources when accuracy is critical.
